{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from diffusers import DDPMScheduler\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from modeling_diffbert import DiffBertForDiffusion\n",
    "from configuration_diffbert import DiffBertConfig\n",
    "import torch\n",
    "import inspect\n",
    "from typing import Any, Callable, Dict, List, Optional, Union\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "# model(inputs_embeds=inputs_embeds, timesteps=timesteps).logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"neuralmind/bert-base-portuguese-cased\")\n",
    "scheduler = DDPMScheduler()\n",
    "model = DiffBertForDiffusion.from_pretrained(\"diffbert-mini-trained\").to(\"cuda\")\n",
    "device = model.device\n",
    "embedding = torch.nn.Embedding(model.config.vocab_size, model.config.hidden_size).to(device)\n",
    "embedding.load_state_dict(torch.load('diffbert-mini/embedding_weights.bin'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def retrieve_timesteps(\n",
    "    scheduler,\n",
    "    num_inference_steps: Optional[int] = None,\n",
    "    device: Optional[Union[str, torch.device]] = None,\n",
    "    timesteps: Optional[List[int]] = None,\n",
    "    **kwargs,\n",
    "):\n",
    "    \"\"\"\n",
    "    Calls the scheduler's `set_timesteps` method and retrieves timesteps from the scheduler after the call. Handles\n",
    "    custom timesteps. Any kwargs will be supplied to `scheduler.set_timesteps`.\n",
    "\n",
    "    Args:\n",
    "        scheduler (`SchedulerMixin`):\n",
    "            The scheduler to get timesteps from.\n",
    "        num_inference_steps (`int`):\n",
    "            The number of diffusion steps used when generating samples with a pre-trained model. If used,\n",
    "            `timesteps` must be `None`.\n",
    "        device (`str` or `torch.device`, *optional*):\n",
    "            The device to which the timesteps should be moved to. If `None`, the timesteps are not moved.\n",
    "        timesteps (`List[int]`, *optional*):\n",
    "                Custom timesteps used to support arbitrary spacing between timesteps. If `None`, then the default\n",
    "                timestep spacing strategy of the scheduler is used. If `timesteps` is passed, `num_inference_steps`\n",
    "                must be `None`.\n",
    "\n",
    "    Returns:\n",
    "        `Tuple[torch.Tensor, int]`: A tuple where the first element is the timestep schedule from the scheduler and the\n",
    "        second element is the number of inference steps.\n",
    "    \"\"\"\n",
    "    if timesteps is not None:\n",
    "        accepts_timesteps = \"timesteps\" in set(inspect.signature(scheduler.set_timesteps).parameters.keys())\n",
    "        if not accepts_timesteps:\n",
    "            raise ValueError(\n",
    "                f\"The current scheduler class {scheduler.__class__}'s `set_timesteps` does not support custom\"\n",
    "                f\" timestep schedules. Please check whether you are using the correct scheduler.\"\n",
    "            )\n",
    "        scheduler.set_timesteps(timesteps=timesteps, device=device, **kwargs)\n",
    "        timesteps = scheduler.timesteps\n",
    "        num_inference_steps = len(timesteps)\n",
    "    else:\n",
    "        scheduler.set_timesteps(num_inference_steps, device=device, **kwargs)\n",
    "        timesteps = scheduler.timesteps\n",
    "    return timesteps, num_inference_steps\n",
    "\n",
    "def id_to_one_hot(token_ids, vocab_size=tokenizer.vocab_size):\n",
    "    one_hot_vectors = []\n",
    "    for token_id in token_ids:\n",
    "        # Create a zero-filled array with length equal to vocab_size\n",
    "        one_hot = torch.zeros(vocab_size)\n",
    "        # Set the value at the index of the token ID to 1\n",
    "        one_hot[token_id] = 1\n",
    "        one_hot_vectors.append(one_hot)\n",
    "    return torch.stack(one_hot_vectors, dim=0)\n",
    "\n",
    "def get_max_indices(list_of_tensors):\n",
    "    max_indices = []\n",
    "    for tensor in list_of_tensors:\n",
    "        # Get the index of the maximum value in the tensor\n",
    "        index = torch.argmax(tensor).item()\n",
    "        max_indices.append(index)\n",
    "    return max_indices\n",
    "# Function to transform vectors back to indices\n",
    "def vectors_to_indices(vectors, embedding):\n",
    "    # Calculate cosine similarity between vectors and all embedding weights\n",
    "    similarity = torch.matmul(vectors, embedding.weight.T)\n",
    "    \n",
    "    # Get the index of the most similar embedding for each vector\n",
    "    indices = torch.argmax(similarity, dim=1)\n",
    "    \n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.7254, 0.0372, 0.0386,  ..., 0.9575, 0.1290, 0.6060],\n",
      "         [0.7589, 0.4363, 0.1371,  ..., 0.2471, 0.7065, 0.2323],\n",
      "         [0.9780, 0.7494, 0.5051,  ..., 0.9611, 0.1641, 0.0235],\n",
      "         ...,\n",
      "         [0.1705, 0.9530, 0.2505,  ..., 0.8179, 0.4565, 0.7365],\n",
      "         [0.8882, 0.5730, 0.7132,  ..., 0.9168, 0.2951, 0.6713],\n",
      "         [0.0859, 0.0052, 0.2802,  ..., 0.0771, 0.6213, 0.9036]]],\n",
      "       device='cuda:0')\n",
      "tensor([999, 998, 997, 996, 995, 994, 993, 992, 991, 990, 989, 988, 987, 986,\n",
      "        985, 984, 983, 982, 981, 980, 979, 978, 977, 976, 975, 974, 973, 972,\n",
      "        971, 970, 969, 968, 967, 966, 965, 964, 963, 962, 961, 960, 959, 958,\n",
      "        957, 956, 955, 954, 953, 952, 951, 950, 949, 948, 947, 946, 945, 944,\n",
      "        943, 942, 941, 940, 939, 938, 937, 936, 935, 934, 933, 932, 931, 930,\n",
      "        929, 928, 927, 926, 925, 924, 923, 922, 921, 920, 919, 918, 917, 916,\n",
      "        915, 914, 913, 912, 911, 910, 909, 908, 907, 906, 905, 904, 903, 902,\n",
      "        901, 900, 899, 898, 897, 896, 895, 894, 893, 892, 891, 890, 889, 888,\n",
      "        887, 886, 885, 884, 883, 882, 881, 880, 879, 878, 877, 876, 875, 874,\n",
      "        873, 872, 871, 870, 869, 868, 867, 866, 865, 864, 863, 862, 861, 860,\n",
      "        859, 858, 857, 856, 855, 854, 853, 852, 851, 850, 849, 848, 847, 846,\n",
      "        845, 844, 843, 842, 841, 840, 839, 838, 837, 836, 835, 834, 833, 832,\n",
      "        831, 830, 829, 828, 827, 826, 825, 824, 823, 822, 821, 820, 819, 818,\n",
      "        817, 816, 815, 814, 813, 812, 811, 810, 809, 808, 807, 806, 805, 804,\n",
      "        803, 802, 801, 800, 799, 798, 797, 796, 795, 794, 793, 792, 791, 790,\n",
      "        789, 788, 787, 786, 785, 784, 783, 782, 781, 780, 779, 778, 777, 776,\n",
      "        775, 774, 773, 772, 771, 770, 769, 768, 767, 766, 765, 764, 763, 762,\n",
      "        761, 760, 759, 758, 757, 756, 755, 754, 753, 752, 751, 750, 749, 748,\n",
      "        747, 746, 745, 744, 743, 742, 741, 740, 739, 738, 737, 736, 735, 734,\n",
      "        733, 732, 731, 730, 729, 728, 727, 726, 725, 724, 723, 722, 721, 720,\n",
      "        719, 718, 717, 716, 715, 714, 713, 712, 711, 710, 709, 708, 707, 706,\n",
      "        705, 704, 703, 702, 701, 700, 699, 698, 697, 696, 695, 694, 693, 692,\n",
      "        691, 690, 689, 688, 687, 686, 685, 684, 683, 682, 681, 680, 679, 678,\n",
      "        677, 676, 675, 674, 673, 672, 671, 670, 669, 668, 667, 666, 665, 664,\n",
      "        663, 662, 661, 660, 659, 658, 657, 656, 655, 654, 653, 652, 651, 650,\n",
      "        649, 648, 647, 646, 645, 644, 643, 642, 641, 640, 639, 638, 637, 636,\n",
      "        635, 634, 633, 632, 631, 630, 629, 628, 627, 626, 625, 624, 623, 622,\n",
      "        621, 620, 619, 618, 617, 616, 615, 614, 613, 612, 611, 610, 609, 608,\n",
      "        607, 606, 605, 604, 603, 602, 601, 600, 599, 598, 597, 596, 595, 594,\n",
      "        593, 592, 591, 590, 589, 588, 587, 586, 585, 584, 583, 582, 581, 580,\n",
      "        579, 578, 577, 576, 575, 574, 573, 572, 571, 570, 569, 568, 567, 566,\n",
      "        565, 564, 563, 562, 561, 560, 559, 558, 557, 556, 555, 554, 553, 552,\n",
      "        551, 550, 549, 548, 547, 546, 545, 544, 543, 542, 541, 540, 539, 538,\n",
      "        537, 536, 535, 534, 533, 532, 531, 530, 529, 528, 527, 526, 525, 524,\n",
      "        523, 522, 521, 520, 519, 518, 517, 516, 515, 514, 513, 512, 511, 510,\n",
      "        509, 508, 507, 506, 505, 504, 503, 502, 501, 500, 499, 498, 497, 496,\n",
      "        495, 494, 493, 492, 491, 490, 489, 488, 487, 486, 485, 484, 483, 482,\n",
      "        481, 480, 479, 478, 477, 476, 475, 474, 473, 472, 471, 470, 469, 468,\n",
      "        467, 466, 465, 464, 463, 462, 461, 460, 459, 458, 457, 456, 455, 454,\n",
      "        453, 452, 451, 450, 449, 448, 447, 446, 445, 444, 443, 442, 441, 440,\n",
      "        439, 438, 437, 436, 435, 434, 433, 432, 431, 430, 429, 428, 427, 426,\n",
      "        425, 424, 423, 422, 421, 420, 419, 418, 417, 416, 415, 414, 413, 412,\n",
      "        411, 410, 409, 408, 407, 406, 405, 404, 403, 402, 401, 400, 399, 398,\n",
      "        397, 396, 395, 394, 393, 392, 391, 390, 389, 388, 387, 386, 385, 384,\n",
      "        383, 382, 381, 380, 379, 378, 377, 376, 375, 374, 373, 372, 371, 370,\n",
      "        369, 368, 367, 366, 365, 364, 363, 362, 361, 360, 359, 358, 357, 356,\n",
      "        355, 354, 353, 352, 351, 350, 349, 348, 347, 346, 345, 344, 343, 342,\n",
      "        341, 340, 339, 338, 337, 336, 335, 334, 333, 332, 331, 330, 329, 328,\n",
      "        327, 326, 325, 324, 323, 322, 321, 320, 319, 318, 317, 316, 315, 314,\n",
      "        313, 312, 311, 310, 309, 308, 307, 306, 305, 304, 303, 302, 301, 300,\n",
      "        299, 298, 297, 296, 295, 294, 293, 292, 291, 290, 289, 288, 287, 286,\n",
      "        285, 284, 283, 282, 281, 280, 279, 278, 277, 276, 275, 274, 273, 272,\n",
      "        271, 270, 269, 268, 267, 266, 265, 264, 263, 262, 261, 260, 259, 258,\n",
      "        257, 256, 255, 254, 253, 252, 251, 250, 249, 248, 247, 246, 245, 244,\n",
      "        243, 242, 241, 240, 239, 238, 237, 236, 235, 234, 233, 232, 231, 230,\n",
      "        229, 228, 227, 226, 225, 224, 223, 222, 221, 220, 219, 218, 217, 216,\n",
      "        215, 214, 213, 212, 211, 210, 209, 208, 207, 206, 205, 204, 203, 202,\n",
      "        201, 200, 199, 198, 197, 196, 195, 194, 193, 192, 191, 190, 189, 188,\n",
      "        187, 186, 185, 184, 183, 182, 181, 180, 179, 178, 177, 176, 175, 174,\n",
      "        173, 172, 171, 170, 169, 168, 167, 166, 165, 164, 163, 162, 161, 160,\n",
      "        159, 158, 157, 156, 155, 154, 153, 152, 151, 150, 149, 148, 147, 146,\n",
      "        145, 144, 143, 142, 141, 140, 139, 138, 137, 136, 135, 134, 133, 132,\n",
      "        131, 130, 129, 128, 127, 126, 125, 124, 123, 122, 121, 120, 119, 118,\n",
      "        117, 116, 115, 114, 113, 112, 111, 110, 109, 108, 107, 106, 105, 104,\n",
      "        103, 102, 101, 100,  99,  98,  97,  96,  95,  94,  93,  92,  91,  90,\n",
      "         89,  88,  87,  86,  85,  84,  83,  82,  81,  80,  79,  78,  77,  76,\n",
      "         75,  74,  73,  72,  71,  70,  69,  68,  67,  66,  65,  64,  63,  62,\n",
      "         61,  60,  59,  58,  57,  56,  55,  54,  53,  52,  51,  50,  49,  48,\n",
      "         47,  46,  45,  44,  43,  42,  41,  40,  39,  38,  37,  36,  35,  34,\n",
      "         33,  32,  31,  30,  29,  28,  27,  26,  25,  24,  23,  22,  21,  20,\n",
      "         19,  18,  17,  16,  15,  14,  13,  12,  11,  10,   9,   8,   7,   6,\n",
      "          5,   4,   3,   2,   1,   0], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f85bb48063a54bc585a59d94a50bce1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "latents = torch.rand((1, 64, 768), device=device)\n",
    "print(latents)\n",
    "num_inference_steps = 1000\n",
    "timesteps=None#[999, 500, 1]\n",
    "timesteps, num_inference_steps = retrieve_timesteps(scheduler, num_inference_steps, device, timesteps)\n",
    "print(timesteps)\n",
    "for i, t in tqdm(enumerate(timesteps)):\n",
    "    # expand the latents if we are doing classifier free guidance\n",
    "    latent_model_input =  latents\n",
    "    latent_model_input = scheduler.scale_model_input(latent_model_input, t)\n",
    "    # predict the noise residual\n",
    "    noise_pred = model(\n",
    "        inputs_embeds=latent_model_input,\n",
    "        timesteps=t.reshape(1,).to(device),\n",
    "        # encoder_hidden_states=prompt_embeds,\n",
    "        # timestep_cond=timestep_cond,\n",
    "        # cross_attention_kwargs=self.cross_attention_kwargs,\n",
    "        # added_cond_kwargs=added_cond_kwargs,\n",
    "        # return_dict=False,\n",
    "    ).logits\n",
    "\n",
    "\n",
    "\n",
    "    # compute the previous noisy sample x_t -> x_t-1\n",
    "    latents = scheduler.step(noise_pred, t, latents, return_dict=False)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.5556,  0.2821,  0.9652,  ..., -0.1067, -0.1024,  0.1055],\n",
       "         [ 0.2921,  0.1844, -0.2657,  ...,  0.5672,  1.0000,  0.3432],\n",
       "         [ 0.4761, -0.1221, -0.2770,  ...,  0.7733,  0.6842,  0.9755],\n",
       "         ...,\n",
       "         [-0.9979, -0.1217,  0.2603,  ...,  0.4429,  0.7443,  0.7620],\n",
       "         [-1.0000, -0.4854,  0.2244,  ..., -0.5563,  0.5207,  0.4344],\n",
       "         [-0.7882, -0.3605,  0.9690,  ...,  0.3023,  0.1312,  0.9118]]],\n",
       "       device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([17597, 20467, 15288,  1202, 21304,  2211,  2782,  9505, 21557,   123,\n",
      "        12680,  9440,   898,  6662, 23797,  1439,  9078,  4707, 10455,  3991,\n",
      "          383,   117,  3752,  9189,   117, 21015,  1422,  6660,   117, 20318,\n",
      "          770,   117, 10970,   128,   117,  1695, 14066, 13962,  5220,   117,\n",
      "          117,   117, 11489,  3978,  7040, 13061,   117,  6855,   301,  9520,\n",
      "        12306,   117, 15365,  2176,  2177,   122,  3702, 18358,   117,  4707,\n",
      "        18775,   225,  1887,  2428], device='cuda:0')\n",
      "pás AbrahamPP aleuar profissaugu peranteUT a Rico Guin si Windows็ min pred fundo Libertadores tentativaec, inferób, Giro Sul sobera,bero já, buraos, pouco efetivo esportiva nós,,, notic Men acel homônimo, frequentvechtmail,indeãosculo e equipes Cis, fundoicargu 〉 revista\n"
     ]
    }
   ],
   "source": [
    "print(vectors_to_indices(latents[0], embedding))\n",
    "print(tokenizer.decode(vectors_to_indices(latents[0], embedding)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectors corresponding to input indices:\n",
      "tensor([[-7.7292e-02,  1.1234e+00, -1.1162e+00,  9.5290e-01,  7.0411e-01,\n",
      "          9.3934e-02,  1.2905e-01, -6.1421e-01, -4.7354e-01,  1.8669e+00,\n",
      "          1.3230e+00,  7.4839e-01,  3.6166e-01, -7.6501e-01, -3.1029e-01,\n",
      "         -1.3262e+00, -1.2330e+00, -2.1209e-01, -1.2452e+00,  6.3154e-01,\n",
      "         -4.2177e-01, -6.7838e-01,  1.8145e-01, -2.4687e-01,  4.7213e-01,\n",
      "          2.9644e-01,  5.5261e-01, -1.4998e+00, -3.2089e-01,  1.9922e+00,\n",
      "         -2.7300e-01, -1.3218e+00, -2.0146e-01,  1.8222e-02, -1.4948e+00,\n",
      "         -5.4760e-01, -3.8630e-01, -6.9837e-01, -1.0270e-01,  8.3724e-01,\n",
      "         -6.1612e-02, -1.1182e+00,  3.0394e+00, -2.8233e-01,  7.6667e-01,\n",
      "         -2.0013e-01,  1.4309e+00, -4.0717e-01, -7.3446e-01,  8.6851e-02],\n",
      "        [-8.8197e-01, -8.1627e-01, -9.9473e-01, -2.0596e-01, -4.3363e-01,\n",
      "         -1.3574e+00,  8.7575e-01,  4.4570e-02,  6.7288e-01, -8.9306e-01,\n",
      "         -5.2451e-01,  6.8276e-02,  9.4779e-01,  8.5183e-01,  1.8238e+00,\n",
      "         -8.1078e-01,  3.2634e-02,  4.0419e-02, -4.5142e-01, -1.1434e+00,\n",
      "          4.7423e-01, -1.3263e+00,  5.2648e-01,  5.5686e-01,  3.4336e-01,\n",
      "         -1.2285e+00, -2.5638e+00, -6.7112e-01, -9.3213e-01,  7.6350e-01,\n",
      "          5.9230e-01,  9.6961e-01,  1.0063e+00, -1.0044e+00,  4.6741e-01,\n",
      "          8.5772e-01, -2.0306e+00,  1.4568e+00,  1.0490e+00, -7.5555e-01,\n",
      "          8.6928e-01,  1.1793e+00, -8.2389e-01,  9.8368e-01, -2.3453e-03,\n",
      "         -3.6195e-01,  6.7647e-02,  9.9563e-01,  4.9906e-01, -6.3485e-01],\n",
      "        [-1.0037e+00,  1.2213e-02,  3.5370e-01,  1.3708e+00,  8.9655e-01,\n",
      "          4.9396e-01,  6.2339e-01, -5.7808e-01,  1.9695e-01, -6.3229e-02,\n",
      "         -4.8823e-01,  1.4844e+00, -7.6281e-01, -1.1291e+00, -1.5135e+00,\n",
      "          7.0173e-01, -5.4904e-01,  6.7051e-01,  7.3987e-01,  8.5169e-01,\n",
      "         -1.5746e+00, -2.1875e-02,  3.7724e-01,  9.0600e-01, -1.3136e+00,\n",
      "         -2.0459e-01,  5.1956e-01, -4.2968e-01,  5.2788e-01,  3.5077e-01,\n",
      "          1.6122e+00,  1.6415e-01, -4.8770e-02, -1.5691e+00, -1.9253e+00,\n",
      "         -2.7641e-01,  2.3915e+00, -5.0840e-01, -5.0205e-01,  3.9166e-01,\n",
      "         -3.8983e+00, -1.4640e-01,  5.3903e-01,  6.1847e-01, -1.7114e-01,\n",
      "          7.0410e-01, -5.9848e-01, -2.4959e+00, -6.8495e-02, -4.1201e-01]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n",
      "\n",
      "Recovered indices from vectors:\n",
      "tensor([ 3,  7, 15])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define the size of vocabulary and embedding dimension\n",
    "vocab_size = 100  # Example vocabulary size\n",
    "embedding_dim = 50  # Example embedding dimension size\n",
    "\n",
    "# Instantiate nn.Embedding module\n",
    "embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "# Random indices for demonstration purposes\n",
    "indices = torch.tensor([3, 7, 15])  # Example input indices\n",
    "\n",
    "# Convert indices to vectors using the embedding layer\n",
    "vectors = embedding(indices)\n",
    "\n",
    "# Display the vectors corresponding to the input indices\n",
    "print(\"Vectors corresponding to input indices:\")\n",
    "print(vectors)\n",
    "\n",
    "# Function to transform vectors back to indices\n",
    "def vectors_to_indices(vectors, embedding):\n",
    "    # Calculate cosine similarity between vectors and all embedding weights\n",
    "    similarity = torch.matmul(vectors, embedding.weight.T)\n",
    "    \n",
    "    # Get the index of the most similar embedding for each vector\n",
    "    indices = torch.argmax(similarity, dim=1)\n",
    "    \n",
    "    return indices\n",
    "\n",
    "# Convert vectors back to indices\n",
    "recovered_indices = vectors_to_indices(vectors, embedding)\n",
    "\n",
    "# Display the indices recovered from vectors\n",
    "print(\"\\nRecovered indices from vectors:\")\n",
    "print(recovered_indices)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
