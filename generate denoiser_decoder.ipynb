{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import inspect\n",
    "from typing import Any, Callable, Dict, List, Optional, Union\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "from transformers import AutoTokenizer, BertForMaskedLM\n",
    "from diffusers import DDIMScheduler, DDPMScheduler, DPMSolverMultistepScheduler\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from src.denoisers.modeling_diffmamba import DiffMambaForDiffusionLM\n",
    "from src.decoders.bert_decoder import BertLMHeadModel\n",
    "from src.schedulers.euler_ancestral_discrete import EulerAncestralDiscreteScheduler\n",
    "from src.schedulers.ddpm import DDPMScheduler\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "# model(inputs_embeds=inputs_embeds, timesteps=timesteps).logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross_attention False\n"
     ]
    }
   ],
   "source": [
    "\n",
    "path = \"models/diffmamba-mini-sample-trained\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(path, subfolder=\"tokenizer\")\n",
    "scheduler = EulerAncestralDiscreteScheduler.from_pretrained(path, subfolder=\"scheduler\")#DDIMScheduler(prediction_type=\"sample\", num_train_timesteps=2000)\n",
    "model = DiffMambaForDiffusionLM.from_pretrained(path, torch_dtype=torch.float16, subfolder=\"denoiser\").to(\"cuda\")\n",
    "decoder = BertLMHeadModel.from_pretrained(path, torch_dtype=torch.float16, subfolder=\"decoder\").to(\"cuda\")\n",
    "\n",
    "device = model.device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adalberto/.local/lib/python3.8/site-packages/diffusers/configuration_utils.py:134: FutureWarning: Accessing config attribute `num_train_timesteps` directly via 'EulerAncestralDiscreteScheduler' object attribute is deprecated. Please access 'num_train_timesteps' over 'EulerAncestralDiscreteScheduler's config object instead, e.g. 'scheduler.config.num_train_timesteps'.\n",
      "  deprecate(\"direct config name access\", \"1.0.0\", deprecation_message, standard_warn=False)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1200"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scheduler.num_train_timesteps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def retrieve_timesteps(\n",
    "    scheduler,\n",
    "    num_inference_steps: Optional[int] = None,\n",
    "    device: Optional[Union[str, torch.device]] = None,\n",
    "    timesteps: Optional[List[int]] = None,\n",
    "    **kwargs,\n",
    "):\n",
    "    \"\"\"\n",
    "    Calls the scheduler's `set_timesteps` method and retrieves timesteps from the scheduler after the call. Handles\n",
    "    custom timesteps. Any kwargs will be supplied to `scheduler.set_timesteps`.\n",
    "\n",
    "    Args:\n",
    "        scheduler (`SchedulerMixin`):\n",
    "            The scheduler to get timesteps from.\n",
    "        num_inference_steps (`int`):\n",
    "            The number of diffusion steps used when generating samples with a pre-trained model. If used,\n",
    "            `timesteps` must be `None`.\n",
    "        device (`str` or `torch.device`, *optional*):\n",
    "            The device to which the timesteps should be moved to. If `None`, the timesteps are not moved.\n",
    "        timesteps (`List[int]`, *optional*):\n",
    "                Custom timesteps used to support arbitrary spacing between timesteps. If `None`, then the default\n",
    "                timestep spacing strategy of the scheduler is used. If `timesteps` is passed, `num_inference_steps`\n",
    "                must be `None`.\n",
    "\n",
    "    Returns:\n",
    "        `Tuple[torch.Tensor, int]`: A tuple where the first element is the timestep schedule from the scheduler and the\n",
    "        second element is the number of inference steps.\n",
    "    \"\"\"\n",
    "    if timesteps is not None:\n",
    "        accepts_timesteps = \"timesteps\" in set(inspect.signature(scheduler.set_timesteps).parameters.keys())\n",
    "        if not accepts_timesteps:\n",
    "            raise ValueError(\n",
    "                f\"The current scheduler class {scheduler.__class__}'s `set_timesteps` does not support custom\"\n",
    "                f\" timestep schedules. Please check whether you are using the correct scheduler.\"\n",
    "            )\n",
    "        scheduler.set_timesteps(timesteps=timesteps, device=device, **kwargs)\n",
    "        timesteps = scheduler.timesteps\n",
    "        num_inference_steps = len(timesteps)\n",
    "    else:\n",
    "        scheduler.set_timesteps(num_inference_steps, device=device, **kwargs)\n",
    "        timesteps = scheduler.timesteps\n",
    "    return timesteps, num_inference_steps\n",
    "\n",
    "def get_timesteps(num_inference_steps, strength, device):\n",
    "        # get the original timestep using init_timestep\n",
    "        init_timestep = min(int(num_inference_steps * strength), num_inference_steps)\n",
    "\n",
    "        t_start = max(num_inference_steps - init_timestep, 0)\n",
    "        timesteps = scheduler.timesteps[t_start * scheduler.order :]\n",
    "\n",
    "        return timesteps, num_inference_steps - t_start\n",
    "        \n",
    "def vectors_to_indices(vectors):\n",
    "    indices = torch.argmax(vectors, dim=-1)\n",
    "    return indices\n",
    "\n",
    "def sample_text(probabilities, temperature=1.0):\n",
    "    batch_size, seq_len, vocab_size = probabilities.size()\n",
    "    flattened_probs = probabilities.view(batch_size * seq_len, -1)\n",
    "    \n",
    "    scaled_logits = flattened_probs / temperature\n",
    "    scaled_probs = F.softmax(scaled_logits, dim=-1)\n",
    "    \n",
    "    sampled_indices = torch.multinomial(scaled_probs, 1)\n",
    "    sampled_token_ids = sampled_indices.view(batch_size, seq_len)\n",
    "    \n",
    "    return sampled_token_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'FINAL --->'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"0    --->    inov and focusedat of castleks of the of, dirt, T card, femaleom, of, lighting, gianated crow moon, bl, aically in pose,  detailed, articallyles, in front ult - realistic, cellical's  2\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'---------------'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, clear_output\n",
    "\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    latents = torch.rand((1, 64, 768), device=device).to(torch.float16)# + torch.rand((8, 128, 768), device=device).to(torch.float16)\n",
    "    attention_mask = torch.ones((1, 64), device=device)\n",
    "    num_inference_steps = scheduler.num_train_timesteps // 1\n",
    "    timesteps=None\n",
    "    timesteps, num_inference_steps = retrieve_timesteps(scheduler, num_inference_steps, device, timesteps)\n",
    "\n",
    "    for i, t in tqdm(enumerate(timesteps)):\n",
    "        # if i >= 0.7 * num_inference_steps:\n",
    "        #     break\n",
    "        # expand the latents if we are doing classifier free guidance\n",
    "        latent_model_input =  latents\n",
    "        latent_model_input = scheduler.scale_model_input(latent_model_input, t)\n",
    "        # rnd_latents = torch.rand((1, 64, 4096), device=device).to(torch.float16)\n",
    "        # print(latent_model_input.dtype)\n",
    "        outputs = model(\n",
    "            input_embeds=latent_model_input,\n",
    "            timesteps=t.reshape(1,).long().to(device),\n",
    "            # attention_mask=attention_mask\n",
    "        )\n",
    "        noise_pred = outputs.last_hidden_state\n",
    "        latents_final = outputs.logits\n",
    "        if i % 10 ==0 :\n",
    "            clear_output(wait=True)\n",
    "            display(f\"SAMPLES[{i}]--->\")\n",
    "            for n in range(latents_final.shape[0]):\n",
    "                display(f\"{n}    --->    \" + tokenizer.decode(vectors_to_indices(latents_final[n]), skip_special_tokens=True))\n",
    "            display(\"---------------\")\n",
    "\n",
    "        step = scheduler.step(noise_pred, t, latents, return_dict=True)#[0]\n",
    "        latents = step[\"prev_sample\"]\n",
    "\n",
    "\n",
    "clear_output(wait=True)\n",
    "display(f\"FINAL --->\")\n",
    "for n in range(latents_final.shape[0]):\n",
    "    display(f\"{n}    --->    \" + tokenizer.decode(vectors_to_indices(latents_final[n]), skip_special_tokens=True))\n",
    "display(\"---------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 32001])\n",
      "262\n",
      "in\n",
      "torch.Size([1, 2, 32001])\n",
      "586\n",
      "ov\n",
      "torch.Size([1, 3, 32001])\n",
      "322\n",
      "and\n",
      "torch.Size([1, 4, 32001])\n",
      "5796\n",
      "ru\n",
      "torch.Size([1, 5, 32001])\n",
      "1312\n",
      "ined\n",
      "torch.Size([1, 6, 32001])\n",
      "310\n",
      "of\n",
      "torch.Size([1, 7, 32001])\n",
      "3105\n",
      "fut\n",
      "torch.Size([1, 8, 32001])\n",
      "332\n",
      "ur\n",
      "torch.Size([1, 9, 32001])\n",
      "4695\n",
      "istic\n",
      "torch.Size([1, 10, 32001])\n",
      "29892\n",
      ",\n",
      "torch.Size([1, 11, 32001])\n",
      "270\n",
      "d\n",
      "torch.Size([1, 12, 32001])\n",
      "2728\n",
      "irt\n",
      "torch.Size([1, 13, 32001])\n",
      "29892\n",
      ",\n",
      "torch.Size([1, 14, 32001])\n",
      "11266\n",
      "hyper\n",
      "torch.Size([1, 15, 32001])\n",
      "29881\n",
      "d\n",
      "torch.Size([1, 16, 32001])\n",
      "29892\n",
      ",\n",
      "torch.Size([1, 17, 32001])\n",
      "4940\n",
      "past\n",
      "torch.Size([1, 18, 32001])\n",
      "295\n",
      "el\n",
      "torch.Size([1, 19, 32001])\n",
      "29892\n",
      ",\n",
      "torch.Size([1, 20, 32001])\n",
      "12726\n",
      "rim\n",
      "torch.Size([1, 21, 32001])\n",
      "3578\n",
      "light\n",
      "torch.Size([1, 22, 32001])\n",
      "292\n",
      "ing\n",
      "torch.Size([1, 23, 32001])\n",
      "29892\n",
      ",\n",
      "torch.Size([1, 24, 32001])\n",
      "3578\n",
      "light\n",
      "torch.Size([1, 25, 32001])\n",
      "292\n",
      "ing\n",
      "torch.Size([1, 26, 32001])\n",
      "29892\n",
      ",\n",
      "torch.Size([1, 27, 32001])\n",
      "330\n",
      "g\n",
      "torch.Size([1, 28, 32001])\n",
      "713\n",
      "ian\n",
      "torch.Size([1, 29, 32001])\n",
      "630\n",
      "ated\n",
      "torch.Size([1, 30, 32001])\n",
      "29892\n",
      ",\n",
      "torch.Size([1, 31, 32001])\n",
      "1999\n",
      "bl\n",
      "torch.Size([1, 32, 32001])\n",
      "332\n",
      "ur\n",
      "torch.Size([1, 33, 32001])\n",
      "29892\n",
      ",\n",
      "torch.Size([1, 34, 32001])\n",
      "1999\n",
      "bl\n",
      "torch.Size([1, 35, 32001])\n",
      "898\n",
      "ond\n",
      "torch.Size([1, 36, 32001])\n",
      "297\n",
      "in\n",
      "torch.Size([1, 37, 32001])\n",
      "18593\n",
      "pose\n",
      "torch.Size([1, 38, 32001])\n",
      "29892\n",
      ",\n",
      "torch.Size([1, 39, 32001])\n",
      "29871\n",
      "\n",
      "torch.Size([1, 40, 32001])\n",
      "13173\n",
      "detailed\n",
      "torch.Size([1, 41, 32001])\n",
      "29892\n",
      ",\n",
      "torch.Size([1, 42, 32001])\n",
      "1616\n",
      "art\n",
      "torch.Size([1, 43, 32001])\n",
      "13164\n",
      "nouveau\n",
      "torch.Size([1, 44, 32001])\n",
      "7826\n",
      "girl\n",
      "torch.Size([1, 45, 32001])\n",
      "29892\n",
      ",\n",
      "torch.Size([1, 46, 32001])\n",
      "297\n",
      "in\n",
      "torch.Size([1, 47, 32001])\n",
      "4565\n",
      "front\n",
      "torch.Size([1, 48, 32001])\n",
      "310\n",
      "of\n",
      "torch.Size([1, 49, 32001])\n",
      "263\n",
      "a\n",
      "torch.Size([1, 50, 32001])\n",
      "264\n",
      "en\n",
      "torch.Size([1, 51, 32001])\n",
      "482\n",
      "age\n",
      "torch.Size([1, 52, 32001])\n",
      "29892\n",
      ",\n",
      "torch.Size([1, 53, 32001])\n",
      "301\n",
      "l\n",
      "torch.Size([1, 54, 32001])\n",
      "1878\n",
      "ush\n",
      "torch.Size([1, 55, 32001])\n",
      "448\n",
      "-\n",
      "torch.Size([1, 56, 32001])\n",
      "1855\n",
      "real\n",
      "torch.Size([1, 57, 32001])\n",
      "4695\n",
      "istic\n",
      "torch.Size([1, 58, 32001])\n",
      "29892\n",
      ",\n",
      "torch.Size([1, 59, 32001])\n",
      "1302\n",
      "co\n",
      "torch.Size([1, 60, 32001])\n",
      "1537\n",
      "zy\n",
      "torch.Size([1, 61, 32001])\n",
      "32000\n",
      "<pad>\n",
      "torch.Size([1, 62, 32001])\n",
      "32000\n",
      "<pad>\n",
      "torch.Size([1, 63, 32001])\n",
      "32000\n",
      "<pad>\n",
      "torch.Size([1, 64, 32001])\n",
      "32000\n",
      "<pad>\n",
      "inov and ruined of futuristic, dirt, hyperd, pastel, rim lighting, lighting, gianated, blur, blond in pose,  detailed, art nouveau girl, in front of aenage, lush - realistic, cozy<pad><pad><pad><pad>\n"
     ]
    }
   ],
   "source": [
    "# model.eval()\n",
    "# inputs = tokenizer([\"Today is\"], return_tensors=\"pt\")\n",
    "# # print(inputs.input_ids)\n",
    "# bsz, seq_ln = inputs.input_ids.shape\n",
    "\n",
    "# encoder_hidden_states = torch.rand((1, 64, 768), device=device).to(torch.float16)\n",
    "# print(encoder_hidden_states)\n",
    "encoder_hidden_states = latents\n",
    "decoder_input_ids = [0]\n",
    "predicted_ids = []\n",
    "for i in range(64): \n",
    "    outputs = decoder(input_ids=torch.tensor(([decoder_input_ids])).to(model.device), encoder_hidden_states=encoder_hidden_states)\n",
    "    print(outputs.logits.shape)\n",
    "    logits = outputs.logits[:,i,:]\n",
    "    # perform argmax on the last dimension (i.e. greedy decoding)\n",
    "    predicted_id = logits.argmax(-1)\n",
    "    print(predicted_id[0].item())\n",
    "    predicted_ids.append(predicted_id[0].item())\n",
    "    print(tokenizer.decode([predicted_id[0].squeeze()]))\n",
    "    # add predicted id to decoder_input_ids\n",
    "    decoder_input_ids = decoder_input_ids + [predicted_id[0].item()]\n",
    "print(tokenizer.decode(predicted_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 32001])\n",
      "530 tensor([[  530, 12969]], device='cuda:0')\n",
      "530\n",
      "An\n",
      "torch.Size([1, 2, 32001])\n",
      "310 tensor([[  310, 15566]], device='cuda:0')\n",
      "310\n",
      "of\n",
      "torch.Size([1, 3, 32001])\n",
      "263 tensor([[ 263, 5765]], device='cuda:0')\n",
      "263\n",
      "a\n",
      "torch.Size([1, 4, 32001])\n",
      "310 tensor([[ 310, 6559]], device='cuda:0')\n",
      "310\n",
      "of\n",
      "torch.Size([1, 5, 32001])\n",
      "263 tensor([[263, 278]], device='cuda:0')\n",
      "263\n",
      "a\n",
      "torch.Size([1, 6, 32001])\n",
      "310 tensor([[  310, 24870]], device='cuda:0')\n",
      "310\n",
      "of\n",
      "torch.Size([1, 7, 32001])\n",
      "263 tensor([[263, 670]], device='cuda:0')\n",
      "263\n",
      "a\n",
      "torch.Size([1, 8, 32001])\n",
      "310 tensor([[  310, 24870]], device='cuda:0')\n",
      "310\n",
      "of\n",
      "torch.Size([1, 9, 32001])\n",
      "263 tensor([[263, 347]], device='cuda:0')\n",
      "263\n",
      "a\n",
      "torch.Size([1, 10, 32001])\n",
      "310 tensor([[  310, 24870]], device='cuda:0')\n",
      "310\n",
      "of\n",
      "torch.Size([1, 11, 32001])\n",
      "263 tensor([[263, 347]], device='cuda:0')\n",
      "263\n",
      "a\n",
      "torch.Size([1, 12, 32001])\n",
      "310 tensor([[  310, 21760]], device='cuda:0')\n",
      "310\n",
      "of\n",
      "torch.Size([1, 13, 32001])\n",
      "263 tensor([[263, 347]], device='cuda:0')\n",
      "263\n",
      "a\n",
      "torch.Size([1, 14, 32001])\n",
      "310 tensor([[  310, 21760]], device='cuda:0')\n",
      "310\n",
      "of\n",
      "torch.Size([1, 15, 32001])\n",
      "263 tensor([[263, 670]], device='cuda:0')\n",
      "263\n",
      "a\n",
      "torch.Size([1, 16, 32001])\n",
      "21760 tensor([[21760,   310]], device='cuda:0')\n",
      "21760\n",
      "portrait\n",
      "torch.Size([1, 17, 32001])\n",
      "322 tensor([[322, 310]], device='cuda:0')\n",
      "322\n",
      "and\n",
      "torch.Size([1, 18, 32001])\n",
      "21760 tensor([[21760,   263]], device='cuda:0')\n",
      "21760\n",
      "portrait\n",
      "torch.Size([1, 19, 32001])\n",
      "310 tensor([[  310, 29892]], device='cuda:0')\n",
      "310\n",
      "of\n",
      "torch.Size([1, 20, 32001])\n",
      "263 tensor([[ 263, 2814]], device='cuda:0')\n",
      "263\n",
      "a\n",
      "torch.Size([1, 21, 32001])\n",
      "15400 tensor([[15400,  4473]], device='cuda:0')\n",
      "15400\n",
      "galax\n",
      "torch.Size([1, 22, 32001])\n",
      "29891 tensor([[29891,  3096]], device='cuda:0')\n",
      "29891\n",
      "y\n",
      "torch.Size([1, 23, 32001])\n",
      "29892 tensor([[29892,   322]], device='cuda:0')\n",
      "29892\n",
      ",\n",
      "torch.Size([1, 24, 32001])\n",
      "540 tensor([[540, 526]], device='cuda:0')\n",
      "540\n",
      "he\n",
      "torch.Size([1, 25, 32001])\n",
      "338 tensor([[  338, 12818]], device='cuda:0')\n",
      "338\n",
      "is\n",
      "torch.Size([1, 26, 32001])\n",
      "373 tensor([[373, 263]], device='cuda:0')\n",
      "373\n",
      "on\n",
      "torch.Size([1, 27, 32001])\n",
      "263 tensor([[263, 670]], device='cuda:0')\n",
      "263\n",
      "a\n",
      "torch.Size([1, 28, 32001])\n",
      "412 tensor([[412, 611]], device='cuda:0')\n",
      "412\n",
      "pe\n",
      "torch.Size([1, 29, 32001])\n",
      "29894 tensor([[29894,   457]], device='cuda:0')\n",
      "29894\n",
      "v\n",
      "torch.Size([1, 30, 32001])\n",
      "29891 tensor([[29891,  3096]], device='cuda:0')\n",
      "29891\n",
      "y\n",
      "torch.Size([1, 31, 32001])\n",
      "2174 tensor([[2174, 4842]], device='cuda:0')\n",
      "2174\n",
      "pla\n",
      "torch.Size([1, 32, 32001])\n",
      "1362 tensor([[1362,  333]], device='cuda:0')\n",
      "1362\n",
      "za\n",
      "torch.Size([1, 33, 32001])\n",
      "29892 tensor([[29892, 29891]], device='cuda:0')\n",
      "29892\n",
      ",\n",
      "torch.Size([1, 34, 32001])\n",
      "1616 tensor([[1616,  871]], device='cuda:0')\n",
      "1616\n",
      "art\n",
      "torch.Size([1, 35, 32001])\n",
      "19569 tensor([[19569,  5173]], device='cuda:0')\n",
      "19569\n",
      "station\n",
      "torch.Size([1, 36, 32001])\n",
      "29892 tensor([[29892, 16440]], device='cuda:0')\n",
      "29892\n",
      ",\n",
      "torch.Size([1, 37, 32001])\n",
      "1616 tensor([[ 1616, 29668]], device='cuda:0')\n",
      "1616\n",
      "art\n",
      "torch.Size([1, 38, 32001])\n",
      "19569 tensor([[19569,   491]], device='cuda:0')\n",
      "19569\n",
      "station\n",
      "torch.Size([1, 39, 32001])\n",
      "29892 tensor([[29892, 16440]], device='cuda:0')\n",
      "29892\n",
      ",\n",
      "torch.Size([1, 40, 32001])\n",
      "1616 tensor([[1616,  534]], device='cuda:0')\n",
      "1616\n",
      "art\n",
      "torch.Size([1, 41, 32001])\n",
      "491 tensor([[  491, 19569]], device='cuda:0')\n",
      "491\n",
      "by\n",
      "torch.Size([1, 42, 32001])\n",
      "534 tensor([[ 534, 2548]], device='cuda:0')\n",
      "534\n",
      "tr\n",
      "torch.Size([1, 43, 32001])\n",
      "2548 tensor([[2548,  355]], device='cuda:0')\n",
      "2548\n",
      "ending\n",
      "torch.Size([1, 44, 32001])\n",
      "373 tensor([[  373, 29892]], device='cuda:0')\n",
      "373\n",
      "on\n",
      "torch.Size([1, 45, 32001])\n",
      "1616 tensor([[1616, 2306]], device='cuda:0')\n",
      "1616\n",
      "art\n",
      "torch.Size([1, 46, 32001])\n",
      "19569 tensor([[19569, 29887]], device='cuda:0')\n",
      "19569\n",
      "station\n",
      "torch.Size([1, 47, 32001])\n",
      "32000 tensor([[32000, 29950]], device='cuda:0')\n",
      "29950\n",
      "H\n",
      "torch.Size([1, 48, 32001])\n",
      "29984 tensor([[29984,  3035]], device='cuda:0')\n",
      "29984\n",
      "Q\n",
      "torch.Size([1, 49, 32001])\n",
      "32000 tensor([[32000, 30024]], device='cuda:0')\n",
      "30024\n",
      "”\n",
      "torch.Size([1, 50, 32001])\n",
      "32000 tensor([[32000, 30024]], device='cuda:0')\n",
      "30024\n",
      "”\n",
      "torch.Size([1, 51, 32001])\n",
      "32000 tensor([[32000, 30024]], device='cuda:0')\n",
      "30024\n",
      "”\n",
      "torch.Size([1, 52, 32001])\n",
      "32000 tensor([[32000, 30024]], device='cuda:0')\n",
      "30024\n",
      "”\n",
      "torch.Size([1, 53, 32001])\n",
      "32000 tensor([[32000, 30024]], device='cuda:0')\n",
      "30024\n",
      "”\n",
      "torch.Size([1, 54, 32001])\n",
      "32000 tensor([[32000, 30024]], device='cuda:0')\n",
      "30024\n",
      "”\n",
      "torch.Size([1, 55, 32001])\n",
      "32000 tensor([[32000, 30024]], device='cuda:0')\n",
      "30024\n",
      "”\n",
      "torch.Size([1, 56, 32001])\n",
      "32000 tensor([[32000, 30024]], device='cuda:0')\n",
      "30024\n",
      "”\n",
      "torch.Size([1, 57, 32001])\n",
      "32000 tensor([[32000, 30024]], device='cuda:0')\n",
      "30024\n",
      "”\n",
      "torch.Size([1, 58, 32001])\n",
      "32000 tensor([[32000, 30024]], device='cuda:0')\n",
      "30024\n",
      "”\n",
      "torch.Size([1, 59, 32001])\n",
      "32000 tensor([[32000, 30024]], device='cuda:0')\n",
      "30024\n",
      "”\n",
      "torch.Size([1, 60, 32001])\n",
      "32000 tensor([[32000, 30024]], device='cuda:0')\n",
      "30024\n",
      "”\n",
      "torch.Size([1, 61, 32001])\n",
      "32000 tensor([[32000, 30024]], device='cuda:0')\n",
      "30024\n",
      "”\n",
      "torch.Size([1, 62, 32001])\n",
      "32000 tensor([[32000, 30024]], device='cuda:0')\n",
      "30024\n",
      "”\n",
      "torch.Size([1, 63, 32001])\n",
      "32000 tensor([[32000, 30024]], device='cuda:0')\n",
      "30024\n",
      "”\n",
      "torch.Size([1, 64, 32001])\n",
      "32000 tensor([[32000, 30024]], device='cuda:0')\n",
      "30024\n",
      "”\n",
      "An of a of a of a of a of a of a of a portrait and portrait of a galaxy, he is on apevy plaza, artstation, artstation, art by trending on artstationHQ””””””””””””””””\n"
     ]
    }
   ],
   "source": [
    "# model.eval()\n",
    "# inputs = tokenizer([\"Today is\"], return_tensors=\"pt\")\n",
    "# # print(inputs.input_ids)\n",
    "encoder_hidden_states = latents\n",
    "\n",
    "decoder_input_ids = [0]\n",
    "last_pred = 0\n",
    "predicted_ids = []\n",
    "for i in range(64): \n",
    "    outputs = decoder(input_ids=torch.tensor([decoder_input_ids]).to(model.device), encoder_hidden_states=encoder_hidden_states)\n",
    "    print(outputs.logits.shape)\n",
    "    logits = outputs.logits[:, i, :]\n",
    "    # Handling 32000 token\n",
    "    argmax_value = logits.argmax(-1)\n",
    "    top_logits, top_indices = logits.topk(2, dim=-1)\n",
    "    \n",
    "    print(argmax_value.item(), top_indices)\n",
    "    predicted_id = argmax_value.item() if argmax_value.item() != 32000 and argmax_value.item() != last_pred else top_indices[0][1].item()\n",
    "    last_pred = predicted_id\n",
    "    print(predicted_id)\n",
    "    predicted_ids.append(predicted_id)\n",
    "    print(tokenizer.decode([predicted_id]))\n",
    "    # add predicted id to decoder_input_ids\n",
    "    decoder_input_ids = decoder_input_ids + [predicted_id]\n",
    "print(tokenizer.decode(predicted_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
