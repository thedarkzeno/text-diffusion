{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from diffusers import DDPMScheduler\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"neuralmind/bert-base-portuguese-cased\")\n",
    "noise_scheduler = DDPMScheduler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PreTrainedTokenizerFast(name_or_path='neuralmind/bert-base-portuguese-cased', vocab_size=29794, model_max_len=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1966,   253,   222,  3515,   125, 13934,  4509,  2066])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_ids(text):\n",
    "    ids = tokenizer(text, add_special_tokens=False, return_tensors=\"pt\").input_ids[0]\n",
    "    return ids\n",
    "    \n",
    "get_ids(\"esse é um teste de difusão textual\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def id_to_one_hot(token_ids, vocab_size=tokenizer.vocab_size):\n",
    "    one_hot_vectors = []\n",
    "    for token_id in token_ids:\n",
    "        # Create a zero-filled array with length equal to vocab_size\n",
    "        one_hot = torch.zeros(vocab_size)\n",
    "        # Set the value at the index of the token ID to 1\n",
    "        one_hot[token_id] = 1\n",
    "        one_hot_vectors.append(one_hot)\n",
    "    return torch.stack(one_hot_vectors, dim=0)\n",
    "id_to_one_hot(get_ids(\"esse é um teste de difusão textual\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise(latents, max_steps=noise_scheduler.config.num_train_timesteps):\n",
    "    noise = torch.randn_like(latents)\n",
    "    bsz = latents.shape[0]\n",
    "    timesteps = torch.randint(0, max_steps, (bsz,), device=latents.device)\n",
    "    timesteps = timesteps.long()\n",
    "    noisy_latents = noise_scheduler.add_noise(latents, noise, timesteps)\n",
    "    return noisy_latents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_indices(list_of_tensors):\n",
    "    max_indices = []\n",
    "    for tensor in list_of_tensors:\n",
    "        # Get the index of the maximum value in the tensor\n",
    "        index = torch.argmax(tensor).item()\n",
    "        max_indices.append(index)\n",
    "    return max_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'esse é um teste de difusão textual'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([1966, 253, 222, 3515, 125, 13934, 4509, 2066])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5295, 253, 13051, 136, 5959, 26104, 19381, 23587]\n",
      "fábr é tribun? Desenvol所 expostosە\n",
      "[23762, 21796, 17740, 12789, 16483, 7904, 9009, 13038]\n",
      "##Ζ Amarties soviética suficientementeap Est ater\n",
      "[5872, 8076, 21164, 17823, 125, 7526, 10297, 6919]\n",
      "##lado 1950 Nickelodeonnautas de Rainhaesses dividido\n",
      "[25467, 16386, 22918, 10950, 737, 13911, 3044, 20802]\n",
      "##ཕ ench本criçãoração governantes Glo 116\n",
      "[3211, 15207, 13166, 3515, 6513, 5532, 21399, 4868]\n",
      "intit Jinftwa testequad golpe interessou Agosto\n",
      "[14559, 5582, 25288, 14735, 27492, 4566, 14349, 2066]\n",
      "dieta Sérӡfam떗 daqueleyoncétual\n",
      "[23677, 23953, 9657, 27111, 12228, 27162, 29774, 9930]\n",
      "##悪艺 esquerdo꾪 abastecimento뇫흹 auxílio\n",
      "[2645, 1886, 3234, 6208, 28752, 19033, 4509, 26152]\n",
      "presença 〈 Ban roteiro찿 verdadeiramente tex握\n",
      "[1072, 253, 24641, 7006, 15283, 6311, 6335, 13652]\n",
      "Pro é併ortaleza árbitroíça formando participado\n",
      "[15307, 29152, 13855, 15256, 27294, 7122, 6336, 22306]\n",
      "nad퀹 agrupaventura돲 minha quadrinhosí\n"
     ]
    }
   ],
   "source": [
    "latents = id_to_one_hot(get_ids(\"esse é um teste de difusão textual\"))\n",
    "\n",
    "for i in range(10):\n",
    "    new = add_noise(latents, 1000)\n",
    "    # print(img2ids(new))\n",
    "    print(get_max_indices(new))\n",
    "    print(tokenizer.decode(get_max_indices(new)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Tensor: tensor([604,  57])\n",
      "tensor([[604, 604, 604, 604],\n",
      "        [ 57,  57,  57,  57]])\n"
     ]
    }
   ],
   "source": [
    "timesteps = torch.randint(0, noise_scheduler.config.num_train_timesteps, (2,))\n",
    "print(\"Original Tensor:\", timesteps)\n",
    "# timesteps_ones = torch.ones(16, dtype=torch.long)\n",
    "# print(timesteps_ones)\n",
    "n_seq = 4  # Define the number of repetitions\n",
    "# timesteps_tensor = timesteps_ones[:n_seq].expand((timesteps.size(0), n_seq))\n",
    "# print(timesteps_tensor)\n",
    "# print(timesteps_tensor)\n",
    "# Repeat each number in timesteps n_seq times\n",
    "repeated_tensor = timesteps.unsqueeze(1).repeat(1, n_seq)\n",
    "\n",
    "print(repeated_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DiffBertForDiffusion(\n",
       "  (bert): DiffBertModel(\n",
       "    (embeddings): DiffBertEmbeddings(\n",
       "      (word_embeddings): Linear(in_features=30522, out_features=384, bias=True)\n",
       "      (position_embeddings): Embedding(512, 384)\n",
       "      (token_type_embeddings): Embedding(2, 384)\n",
       "      (time_embedding): Embedding(1000, 384)\n",
       "      (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): DiffBertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-1): 2 x DiffBertLayer(\n",
       "          (attention): DiffBertAttention(\n",
       "            (self): DiffBertSelfAttention(\n",
       "              (query): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (key): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (value): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): DiffBertSelfOutput(\n",
       "              (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DiffBertIntermediate(\n",
       "            (dense): Linear(in_features=384, out_features=768, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DiffBertOutput(\n",
       "            (dense): Linear(in_features=768, out_features=384, bias=True)\n",
       "            (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (cls): Linear(in_features=384, out_features=30522, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from modeling_diffbert import DiffBertForDiffusion\n",
    "from configuration_diffbert import DiffBertConfig\n",
    "import torch\n",
    "\n",
    "model = DiffBertForDiffusion.from_pretrained(\"diffbert-mini\")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 128, 30522])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_embeds = torch.rand((4, 128, 30522))\n",
    "timesteps = torch.randint(0, noise_scheduler.config.num_train_timesteps, (4,))\n",
    "model(inputs_embeds=inputs_embeds, timesteps=timesteps).logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import StringIO\n",
    "import sys\n",
    "\n",
    "notebooks = {}\n",
    "def create_notebook(notebook_id):\n",
    "    notebooks[notebook_id] = {'variables': {}}\n",
    "    return f\"Notebook {notebook_id} created successfully!\"\n",
    "\n",
    "def run_code(notebook_id, code):\n",
    "\n",
    "    variables = notebooks.get(notebook_id).get('variables')\n",
    "    \n",
    "    # Redirect stdout to capture output\n",
    "    sys.stdout = StringIO()\n",
    "    \n",
    "    try:\n",
    "        exec(code, variables)\n",
    "        output = sys.stdout.getvalue()\n",
    "    except Exception as e:\n",
    "        output = f\"Error: {str(e)}\"\n",
    "    \n",
    "    # Restore stdout\n",
    "    sys.stdout = sys.__stdout__\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Notebook test created successfully!'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_notebook(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = run_code(\"test\", \n",
    "\"\"\"x = 5\n",
    "for i in range(x):\n",
    "    print(i)\n",
    "\"\"\")\n",
    "print(\"output\", out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test': {'variables': {'__builtins__': {'__name__': 'builtins',\n",
       "    '__doc__': \"Built-in functions, exceptions, and other objects.\\n\\nNoteworthy: None is the `nil' object; Ellipsis represents `...' in slices.\",\n",
       "    '__package__': '',\n",
       "    '__loader__': _frozen_importlib.BuiltinImporter,\n",
       "    '__spec__': ModuleSpec(name='builtins', loader=<class '_frozen_importlib.BuiltinImporter'>, origin='built-in'),\n",
       "    '__build_class__': <function __build_class__>,\n",
       "    '__import__': <function __import__>,\n",
       "    'abs': <function abs(x, /)>,\n",
       "    'all': <function all(iterable, /)>,\n",
       "    'any': <function any(iterable, /)>,\n",
       "    'ascii': <function ascii(obj, /)>,\n",
       "    'bin': <function bin(number, /)>,\n",
       "    'breakpoint': <function breakpoint>,\n",
       "    'callable': <function callable(obj, /)>,\n",
       "    'chr': <function chr(i, /)>,\n",
       "    'compile': <function compile(source, filename, mode, flags=0, dont_inherit=False, optimize=-1, *, _feature_version=-1)>,\n",
       "    'delattr': <function delattr(obj, name, /)>,\n",
       "    'dir': <function dir>,\n",
       "    'divmod': <function divmod(x, y, /)>,\n",
       "    'eval': <function eval(source, globals=None, locals=None, /)>,\n",
       "    'exec': <function exec(source, globals=None, locals=None, /)>,\n",
       "    'format': <function format(value, format_spec='', /)>,\n",
       "    'getattr': <function getattr>,\n",
       "    'globals': <function globals()>,\n",
       "    'hasattr': <function hasattr(obj, name, /)>,\n",
       "    'hash': <function hash(obj, /)>,\n",
       "    'hex': <function hex(number, /)>,\n",
       "    'id': <function id(obj, /)>,\n",
       "    'input': <bound method Kernel.raw_input of <ipykernel.ipkernel.IPythonKernel object at 0x1077b6ee0>>,\n",
       "    'isinstance': <function isinstance(obj, class_or_tuple, /)>,\n",
       "    'issubclass': <function issubclass(cls, class_or_tuple, /)>,\n",
       "    'iter': <function iter>,\n",
       "    'len': <function len(obj, /)>,\n",
       "    'locals': <function locals()>,\n",
       "    'max': <function max>,\n",
       "    'min': <function min>,\n",
       "    'next': <function next>,\n",
       "    'oct': <function oct(number, /)>,\n",
       "    'ord': <function ord(c, /)>,\n",
       "    'pow': <function pow(base, exp, mod=None)>,\n",
       "    'print': <function print>,\n",
       "    'repr': <function repr(obj, /)>,\n",
       "    'round': <function round(number, ndigits=None)>,\n",
       "    'setattr': <function setattr(obj, name, value, /)>,\n",
       "    'sorted': <function sorted(iterable, /, *, key=None, reverse=False)>,\n",
       "    'sum': <function sum(iterable, /, start=0)>,\n",
       "    'vars': <function vars>,\n",
       "    'None': None,\n",
       "    'Ellipsis': Ellipsis,\n",
       "    'NotImplemented': NotImplemented,\n",
       "    'False': False,\n",
       "    'True': True,\n",
       "    'bool': bool,\n",
       "    'memoryview': memoryview,\n",
       "    'bytearray': bytearray,\n",
       "    'bytes': bytes,\n",
       "    'classmethod': classmethod,\n",
       "    'complex': complex,\n",
       "    'dict': dict,\n",
       "    'enumerate': enumerate,\n",
       "    'filter': filter,\n",
       "    'float': float,\n",
       "    'frozenset': frozenset,\n",
       "    'property': property,\n",
       "    'int': int,\n",
       "    'list': list,\n",
       "    'map': map,\n",
       "    'object': object,\n",
       "    'range': range,\n",
       "    'reversed': reversed,\n",
       "    'set': set,\n",
       "    'slice': slice,\n",
       "    'staticmethod': staticmethod,\n",
       "    'str': str,\n",
       "    'super': super,\n",
       "    'tuple': tuple,\n",
       "    'type': type,\n",
       "    'zip': zip,\n",
       "    '__debug__': True,\n",
       "    'BaseException': BaseException,\n",
       "    'Exception': Exception,\n",
       "    'TypeError': TypeError,\n",
       "    'StopAsyncIteration': StopAsyncIteration,\n",
       "    'StopIteration': StopIteration,\n",
       "    'GeneratorExit': GeneratorExit,\n",
       "    'SystemExit': SystemExit,\n",
       "    'KeyboardInterrupt': KeyboardInterrupt,\n",
       "    'ImportError': ImportError,\n",
       "    'ModuleNotFoundError': ModuleNotFoundError,\n",
       "    'OSError': OSError,\n",
       "    'EnvironmentError': OSError,\n",
       "    'IOError': OSError,\n",
       "    'EOFError': EOFError,\n",
       "    'RuntimeError': RuntimeError,\n",
       "    'RecursionError': RecursionError,\n",
       "    'NotImplementedError': NotImplementedError,\n",
       "    'NameError': NameError,\n",
       "    'UnboundLocalError': UnboundLocalError,\n",
       "    'AttributeError': AttributeError,\n",
       "    'SyntaxError': SyntaxError,\n",
       "    'IndentationError': IndentationError,\n",
       "    'TabError': TabError,\n",
       "    'LookupError': LookupError,\n",
       "    'IndexError': IndexError,\n",
       "    'KeyError': KeyError,\n",
       "    'ValueError': ValueError,\n",
       "    'UnicodeError': UnicodeError,\n",
       "    'UnicodeEncodeError': UnicodeEncodeError,\n",
       "    'UnicodeDecodeError': UnicodeDecodeError,\n",
       "    'UnicodeTranslateError': UnicodeTranslateError,\n",
       "    'AssertionError': AssertionError,\n",
       "    'ArithmeticError': ArithmeticError,\n",
       "    'FloatingPointError': FloatingPointError,\n",
       "    'OverflowError': OverflowError,\n",
       "    'ZeroDivisionError': ZeroDivisionError,\n",
       "    'SystemError': SystemError,\n",
       "    'ReferenceError': ReferenceError,\n",
       "    'MemoryError': MemoryError,\n",
       "    'BufferError': BufferError,\n",
       "    'Warning': Warning,\n",
       "    'UserWarning': UserWarning,\n",
       "    'DeprecationWarning': DeprecationWarning,\n",
       "    'PendingDeprecationWarning': PendingDeprecationWarning,\n",
       "    'SyntaxWarning': SyntaxWarning,\n",
       "    'RuntimeWarning': RuntimeWarning,\n",
       "    'FutureWarning': FutureWarning,\n",
       "    'ImportWarning': ImportWarning,\n",
       "    'UnicodeWarning': UnicodeWarning,\n",
       "    'BytesWarning': BytesWarning,\n",
       "    'ResourceWarning': ResourceWarning,\n",
       "    'ConnectionError': ConnectionError,\n",
       "    'BlockingIOError': BlockingIOError,\n",
       "    'BrokenPipeError': BrokenPipeError,\n",
       "    'ChildProcessError': ChildProcessError,\n",
       "    'ConnectionAbortedError': ConnectionAbortedError,\n",
       "    'ConnectionRefusedError': ConnectionRefusedError,\n",
       "    'ConnectionResetError': ConnectionResetError,\n",
       "    'FileExistsError': FileExistsError,\n",
       "    'FileNotFoundError': FileNotFoundError,\n",
       "    'IsADirectoryError': IsADirectoryError,\n",
       "    'NotADirectoryError': NotADirectoryError,\n",
       "    'InterruptedError': InterruptedError,\n",
       "    'PermissionError': PermissionError,\n",
       "    'ProcessLookupError': ProcessLookupError,\n",
       "    'TimeoutError': TimeoutError,\n",
       "    'open': <function io.open(file, mode='r', buffering=-1, encoding=None, errors=None, newline=None, closefd=True, opener=None)>,\n",
       "    'copyright': Copyright (c) 2001-2022 Python Software Foundation.\n",
       "    All Rights Reserved.\n",
       "    \n",
       "    Copyright (c) 2000 BeOpen.com.\n",
       "    All Rights Reserved.\n",
       "    \n",
       "    Copyright (c) 1995-2001 Corporation for National Research Initiatives.\n",
       "    All Rights Reserved.\n",
       "    \n",
       "    Copyright (c) 1991-1995 Stichting Mathematisch Centrum, Amsterdam.\n",
       "    All Rights Reserved.,\n",
       "    'credits':     Thanks to CWI, CNRI, BeOpen.com, Zope Corporation and a cast of thousands\n",
       "        for supporting Python development.  See www.python.org for more information.,\n",
       "    'license': Type license() to see the full license text,\n",
       "    'help': Type help() for interactive help, or help(object) for help about object.,\n",
       "    'execfile': <function _pydev_bundle._pydev_execfile.execfile(file, glob=None, loc=None)>,\n",
       "    'runfile': <function _pydev_bundle.pydev_umd.runfile(filename, args=None, wdir=None, namespace=None)>,\n",
       "    '__IPYTHON__': True,\n",
       "    'display': <function IPython.core.display_functions.display(*objs, include=None, exclude=None, metadata=None, transient=None, display_id=None, raw=False, clear=False, **kwargs)>,\n",
       "    '__pybind11_internals_v4_clang_libcpp_cxxabi1002__': <capsule object NULL at 0x10d59ffc0>,\n",
       "    'get_ipython': <bound method InteractiveShell.get_ipython of <ipykernel.zmqshell.ZMQInteractiveShell object at 0x1078bf670>>},\n",
       "   'x': 5,\n",
       "   'i': 4}}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "notebooks"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c6e4e9f98eb68ad3b7c296f83d20e6de614cb42e90992a65aa266555a3137d0d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
